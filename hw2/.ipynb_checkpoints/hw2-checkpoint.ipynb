{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class featureExtraction:\n",
    "    def __init__(self, name):\n",
    "        self.fileName = name\n",
    "        self.review = []\n",
    "        self.ID = []\n",
    "        self.label = []\n",
    "        self.posWords = []\n",
    "        self.negWords = []\n",
    "        self.features = []\n",
    "        self.ID_Review = []\n",
    "    \n",
    "    def readReview(self):\n",
    "        with open(self.fileName, 'r') as fp:\n",
    "            for i,line in enumerate(fp):\n",
    "                #split ID and review\n",
    "                self.ID_Review = line.split('\\t')\n",
    "                self.ID.append(self.ID_Review[0])\n",
    "                self.review.append(self.ID_Review[1].rstrip('\\n')) \n",
    "        if self.fileName == \"hotelPosT-train.txt\":\n",
    "            self.label = [1]*len(self.review)\n",
    "        elif self.fileName == \"hotelNegT-train.txt\":\n",
    "            self.label = [0]*len(self.review)\n",
    "        \n",
    "        return self.ID, self.review, self.label\n",
    "                \n",
    "    def readNegPosWords(self):\n",
    "        with open(\"positive-words.txt\", 'r') as fp:\n",
    "            self.posWords=[]\n",
    "            for i,line in enumerate(fp):\n",
    "                self.posWords.append(line.rstrip('\\n'))\n",
    "        with open(\"negative-words.txt\", 'r') as fp:\n",
    "            self.negWords=[]\n",
    "            for i,line in enumerate(fp):\n",
    "                self.negWords.append(line.rstrip('\\n'))\n",
    "                \n",
    "    def extractFeatures(self,review):\n",
    "        \n",
    "        for r in review:\n",
    "            wordList = r.split()\n",
    "            pronouns = [\"i\", \"me\", \"mine\", \"my\", \"you\", \"your\", \"yours\", \"we\", \"us\", \"ours\"]\n",
    "            \n",
    "            #feature 6:\n",
    "            logWordCount = math.log(len(wordList))\n",
    "        \n",
    "            posCount = 0\n",
    "            negCount = 0\n",
    "            noInOrNot = 0\n",
    "            excMarkInOrNot = 0\n",
    "            pronounsCount = 0\n",
    "            \n",
    "            for word in wordList:\n",
    "                #feature 5:\n",
    "                if '!' in word:\n",
    "                    excMarkInOrNot = 1\n",
    "                    \n",
    "                #feature 4:\n",
    "                if (word.lower() in pronouns) or ('\\'' in word and word.split('\\'')[0].lower() in pronouns):\n",
    "                    pronounsCount += 1\n",
    "                    \n",
    "                #remove punctuation\n",
    "                punc = string.punctuation\n",
    "                punc = punc.replace('-','') # for some special cases like \"kid-friendly\"\n",
    "                word = word.translate(str.maketrans('', '', punc))\n",
    "        \n",
    "                #feature 1:\n",
    "                if word.lower() in self.posWords:\n",
    "                    posCount += 1\n",
    "                \n",
    "                #feature 2:\n",
    "                if word.lower() in self.negWords:\n",
    "                    negCount += 1\n",
    "                    \n",
    "                #feature 3:\n",
    "                if word.lower()=='no':\n",
    "                    noInOrNot = 1\n",
    "                    \n",
    "            self.features.append([posCount, negCount, noInOrNot, pronounsCount, excMarkInOrNot, logWordCount])\n",
    "            \n",
    "        return self.features\n",
    "\n",
    "def writeToCSV(ID,features,label):\n",
    "    #arrange format: ID+feature+label\n",
    "    writeToCSV_format = []\n",
    "    for i in range(len(ID)):\n",
    "        writeToCSV_format.append([ID[i]]+features[i]+[label[i]])\n",
    "    with open('feature.csv','w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(writeToCSV_format)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "posFeature = featureExtraction(\"hotelPosT-train.txt\")\n",
    "posID, posReview, posLabel = posFeature.readReview()\n",
    "posFeature.readNegPosWords()\n",
    "posFeatures = posFeature.extractFeatures(posReview)\n",
    "\n",
    "negFeature = featureExtraction(\"hotelNegT-train.txt\")\n",
    "negID, negReview, negLabel = negFeature.readReview()\n",
    "negFeature.readNegPosWords()\n",
    "negFeatures = negFeature.extractFeatures(negReview)\n",
    "\n",
    "#write to features to feature.csv\n",
    "writeToCSV(posID+negID, posFeatures+negFeatures, posLabel+negLabel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    def __init__(self, train_set, test_set, eta=0.1):\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set \n",
    "        \n",
    "        self.w = np.zeros_like(train_set[0].x)\n",
    "\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.train_acc = []\n",
    "        self.test_acc = []  \n",
    "        self.train_nll = []\n",
    "        self.test_nll = []\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "\n",
    "        return 1.0 / (1.0 + np.exp(-x)) \n",
    "\n",
    "    def compute_progress(self, examples):\n",
    "        #loss\n",
    "        NLL = 0.0\n",
    "        #accuracy\n",
    "        num_correct = 0\n",
    "        for ex in examples:\n",
    "            # compute prob prediction\n",
    "            p = self.sigmoid(self.w.dot(ex.x))\n",
    "            # update negative log likelihood\n",
    "            NLL = NLL - np.log(p) if ex.y==1 else NLL - np.log(1.0-p)\n",
    "            # update number correct \n",
    "            num_correct += 1 if np.floor(p+.5)==ex.y else 0\n",
    "\n",
    "        return NLL, float(num_correct) / float(len(examples))\n",
    "    \n",
    "    def train(self, num_epochs=5, isVerbose=False, report_step=5):\n",
    "    \n",
    "        iteration = 0\n",
    "        for pp in range(num_epochs):\n",
    "            # shuffle the data  \n",
    "            np.random.shuffle(self.train_set)\n",
    "            # loop over each training example\n",
    "            for ex in self.train_set:\n",
    "                # perform SGD update of weights \n",
    "                self.sgd_update(ex)\n",
    "                # record progress \n",
    "                if iteration % report_step == 1:\n",
    "                    train_nll, train_acc = self.compute_progress(self.train_set)\n",
    "                    self.train_nll.append(train_nll)\n",
    "                    self.train_acc.append(train_acc)\n",
    "                    if isVerbose:\n",
    "                        print(\"Update {: 5d}  TrnLoss {: 8.3f}  TrnAcc {:.3f}\"\n",
    "                             .format(iteration-1, train_nll, train_acc))\n",
    "                iteration += 1\n",
    "    \n",
    "    def sgd_update(self, train_example):\n",
    "        \n",
    "        sig_minus_y = self.sigmoid(self.w.dot(train_example.x))-train_example.y\n",
    "        for k in np.nonzero(train_example.x)[0]:\n",
    "            #unregularized part\n",
    "            gradient = sig_minus_y*train_example.x[k]\n",
    "            self.w[k] = self.w[k]-self.eta*gradient\n",
    "            \n",
    "    def test(self, threshold = 0.5):\n",
    "        #accuracy\n",
    "        num_correct = 0\n",
    "        #loss\n",
    "        NLL = 0.0\n",
    "        \n",
    "        #test set label list\n",
    "        labelList = []\n",
    "        \n",
    "        \n",
    "        # test set label is null:\n",
    "        if self.test_set[0].y == -1:\n",
    "            for ex in self.test_set:\n",
    "            # compute prob prediction\n",
    "                p = self.sigmoid(self.w.dot(ex.x))\n",
    "                if p >= threshold:\n",
    "                    labelList.append('POS')\n",
    "                else:\n",
    "                    labelList.append('NEG')\n",
    "            return labelList\n",
    "        \n",
    "        #dev set\n",
    "        else:\n",
    "            for ex in self.test_set:\n",
    "            # compute prob prediction\n",
    "                p = self.sigmoid(self.w.dot(ex.x))\n",
    "            # update negative log likelihood\n",
    "                NLL = NLL - np.log(p) if ex.y==1 else NLL - np.log(1.0-p)\n",
    "            # update number correct \n",
    "                num_correct += 1 if np.floor(p+.5)==ex.y else 0              \n",
    "            print(\"dev Set Loss:\" + str(NLL) +\"  dev Set Accuracy: \" +str(float(num_correct) / float(len(self.test_set))))       \n",
    "            return []\n",
    "\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read trainset and devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self, label, features):\n",
    "        self.y = label\n",
    "        self.x = features\n",
    "        \n",
    "def readFile(name):\n",
    "    data = []\n",
    "    with open(name, 'r') as fp:\n",
    "        for i,line in enumerate(fp):\n",
    "            arr = line.split(',')\n",
    "            #print(dataset(arr[-1], arr[1:-1]).x)\n",
    "            data.append(dataset(int(arr[-1].rstrip('\\n')), list(np.array(arr[1:-1]).astype(np.float))))\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test set\n",
    "def getTrainTestSet(fileName):\n",
    "    allData = readFile(fileName)\n",
    "    np.random.shuffle(allData)\n",
    "    trainSet = allData[0:int(0.8*len(allData))]\n",
    "    devSet = allData[int(0.8*len(allData)):]\n",
    "    \n",
    "    return trainSet, devSet\n",
    "\n",
    "trainSet, devSet = getTrainTestSet(\"feature.csv\")\n",
    "#bias\n",
    "for i in range(len(trainSet)):\n",
    "    trainSet[i].x = trainSet[i].x+[1]\n",
    "for i in range(len(devSet)):\n",
    "    devSet[i].x = devSet[i].x+[1]   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update     0  TrnLoss  104.549  TrnAcc 0.483\n",
      "Update   200  TrnLoss   65.082  TrnAcc 0.874\n",
      "Update   400  TrnLoss   53.881  TrnAcc 0.887\n",
      "Update   600  TrnLoss   47.313  TrnAcc 0.914\n",
      "Update   800  TrnLoss   43.749  TrnAcc 0.907\n",
      "Update  1000  TrnLoss   41.635  TrnAcc 0.907\n",
      "Update  1200  TrnLoss   39.905  TrnAcc 0.921\n",
      "Update  1400  TrnLoss   38.600  TrnAcc 0.921\n",
      "Update  1600  TrnLoss   37.584  TrnAcc 0.927\n",
      "Update  1800  TrnLoss   36.729  TrnAcc 0.927\n",
      "Update  2000  TrnLoss   35.998  TrnAcc 0.927\n",
      "Update  2200  TrnLoss   35.437  TrnAcc 0.927\n",
      "Update  2400  TrnLoss   35.053  TrnAcc 0.940\n",
      "Update  2600  TrnLoss   34.731  TrnAcc 0.921\n",
      "Update  2800  TrnLoss   34.178  TrnAcc 0.927\n",
      "Update  3000  TrnLoss   33.871  TrnAcc 0.934\n",
      "Update  3200  TrnLoss   33.838  TrnAcc 0.934\n",
      "Update  3400  TrnLoss   33.591  TrnAcc 0.934\n",
      "Update  3600  TrnLoss   33.154  TrnAcc 0.927\n",
      "Update  3800  TrnLoss   32.884  TrnAcc 0.927\n",
      "Update  4000  TrnLoss   32.712  TrnAcc 0.927\n",
      "Update  4200  TrnLoss   32.463  TrnAcc 0.927\n",
      "Update  4400  TrnLoss   32.341  TrnAcc 0.927\n",
      "Update  4600  TrnLoss   32.190  TrnAcc 0.927\n",
      "Update  4800  TrnLoss   32.046  TrnAcc 0.927\n",
      "Update  5000  TrnLoss   31.963  TrnAcc 0.927\n",
      "Update  5200  TrnLoss   31.781  TrnAcc 0.927\n",
      "Update  5400  TrnLoss   31.714  TrnAcc 0.927\n",
      "Update  5600  TrnLoss   31.745  TrnAcc 0.934\n",
      "Update  5800  TrnLoss   31.479  TrnAcc 0.927\n",
      "Update  6000  TrnLoss   31.794  TrnAcc 0.934\n",
      "Update  6200  TrnLoss   31.390  TrnAcc 0.927\n",
      "Update  6400  TrnLoss   31.630  TrnAcc 0.927\n",
      "Update  6600  TrnLoss   31.165  TrnAcc 0.927\n",
      "Update  6800  TrnLoss   31.084  TrnAcc 0.927\n",
      "Update  7000  TrnLoss   31.345  TrnAcc 0.934\n",
      "Update  7200  TrnLoss   30.957  TrnAcc 0.927\n",
      "Update  7400  TrnLoss   30.892  TrnAcc 0.927\n",
      "Update  7600  TrnLoss   30.866  TrnAcc 0.927\n",
      "Update  7800  TrnLoss   30.821  TrnAcc 0.927\n",
      "Update  8000  TrnLoss   30.857  TrnAcc 0.934\n",
      "Update  8200  TrnLoss   30.845  TrnAcc 0.934\n",
      "Update  8400  TrnLoss   30.618  TrnAcc 0.927\n",
      "Update  8600  TrnLoss   30.590  TrnAcc 0.927\n",
      "Update  8800  TrnLoss   30.525  TrnAcc 0.927\n",
      "Update  9000  TrnLoss   30.502  TrnAcc 0.927\n",
      "Update  9200  TrnLoss   30.453  TrnAcc 0.927\n",
      "Update  9400  TrnLoss   30.408  TrnAcc 0.927\n",
      "Update  9600  TrnLoss   30.408  TrnAcc 0.927\n",
      "Update  9800  TrnLoss   30.347  TrnAcc 0.927\n",
      "Update  10000  TrnLoss   30.309  TrnAcc 0.927\n",
      "Update  10200  TrnLoss   30.295  TrnAcc 0.927\n",
      "Update  10400  TrnLoss   30.276  TrnAcc 0.927\n",
      "Update  10600  TrnLoss   30.239  TrnAcc 0.927\n",
      "Update  10800  TrnLoss   30.312  TrnAcc 0.934\n",
      "Update  11000  TrnLoss   30.209  TrnAcc 0.927\n",
      "Update  11200  TrnLoss   30.171  TrnAcc 0.934\n",
      "Update  11400  TrnLoss   30.113  TrnAcc 0.927\n",
      "Update  11600  TrnLoss   30.109  TrnAcc 0.927\n",
      "Update  11800  TrnLoss   30.059  TrnAcc 0.927\n",
      "Update  12000  TrnLoss   30.239  TrnAcc 0.921\n",
      "Update  12200  TrnLoss   30.032  TrnAcc 0.927\n",
      "Update  12400  TrnLoss   30.002  TrnAcc 0.927\n",
      "Update  12600  TrnLoss   30.003  TrnAcc 0.934\n",
      "Update  12800  TrnLoss   30.000  TrnAcc 0.927\n",
      "Update  13000  TrnLoss   29.918  TrnAcc 0.927\n",
      "Update  13200  TrnLoss   30.014  TrnAcc 0.934\n",
      "Update  13400  TrnLoss   29.965  TrnAcc 0.927\n",
      "Update  13600  TrnLoss   29.879  TrnAcc 0.927\n",
      "Update  13800  TrnLoss   30.197  TrnAcc 0.914\n",
      "Update  14000  TrnLoss   29.922  TrnAcc 0.934\n",
      "Update  14200  TrnLoss   29.811  TrnAcc 0.927\n",
      "Update  14400  TrnLoss   29.818  TrnAcc 0.934\n",
      "Update  14600  TrnLoss   29.788  TrnAcc 0.927\n",
      "Update  14800  TrnLoss   29.760  TrnAcc 0.927\n",
      "Update  15000  TrnLoss   29.752  TrnAcc 0.934\n",
      "dev Set Loss:17.820046492730576  dev Set Accuracy: 0.9210526315789473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogReg(trainSet, devSet, 0.001)\n",
    "LR.train(num_epochs=100, isVerbose=True, report_step = 200)\n",
    "LR.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
